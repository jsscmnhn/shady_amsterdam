{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T07:50:32.792672Z",
     "start_time": "2024-10-21T07:50:32.772832Z"
    }
   },
   "source": [
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import glob\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "def download_and_extract(url, file_path, output_folder):\n",
    "    \"\"\"Download a ZIP file from a URL, extract its contents, and delete the ZIP file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        try:\n",
    "            print(f\"Downloading from {url}...\")\n",
    "            response = requests.get(url, verify=False)  # Bypass SSL verification\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded and saved to {file_path}\")\n",
    "\n",
    "            # Extract the ZIP file\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(output_folder)  # Extract to the output folder\n",
    "            print(f\"Extracted {file_path}\")\n",
    "\n",
    "            # Remove the ZIP file after extraction\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted the ZIP file: {file_path}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {url}: {e}\")\n",
    "        except zipfile.BadZipFile as e:\n",
    "            print(f\"Failed to extract {file_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def merge_tif_files(input_folder, output_file, file_prefix, nodata_value=-9999):\n",
    "    \"\"\"Merge TIF files in a folder with a specific prefix into a single raster file.\n",
    "    ------\n",
    "    Input:\n",
    "    - input_folder (str): Path to the folder containing the TIF files.\n",
    "    - output_file (str): Path to the output raster file.\n",
    "    - file_prefix (str): Prefix of files to merge (\"M_\" for DTM or \"R_\" for DSM).\n",
    "    - nodata_value (int, optional): Value to replace the nodata value. Defaults to -9999.\n",
    "\n",
    "    Output:\n",
    "    - tile_bounds (list): List containing the name of the tile and the extent of that tile, for downloading the buidling data.\n",
    "    - The function writes the merged file directly to the specified `output_file`.\n",
    "    \"\"\"\n",
    "    # Find TIF files that match the given prefix\n",
    "    tif_files = glob.glob(os.path.join(input_folder, f'{file_prefix}*.TIF'))\n",
    "\n",
    "    tile_bounds = []\n",
    "\n",
    "    if not tif_files:\n",
    "        print(f\"No TIF files found for prefix {file_prefix}.\")\n",
    "        return\n",
    "\n",
    "    src_files_to_mosaic = []\n",
    "\n",
    "    for tif_file in tif_files:\n",
    "        src = rasterio.open(tif_file)\n",
    "\n",
    "        # Extract the tile name & \n",
    "        base_name = os.path.basename(tif_file)\n",
    "        tile_name = base_name.split('_', 1)[-1].split('.')[0]\n",
    "        tile_bounds.append([tile_name, src.bounds])\n",
    "\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    mosaic, out_transform = merge(src_files_to_mosaic)\n",
    "\n",
    "    # Replace existing nodata values with new nodata value\n",
    "    for src in src_files_to_mosaic:\n",
    "        if 'nodata' in src.meta:\n",
    "            mosaic[mosaic == src.nodata] = nodata_value\n",
    "\n",
    "    out_meta = src_files_to_mosaic[0].meta.copy()\n",
    "\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": mosaic.shape[1],\n",
    "        \"width\": mosaic.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"count\": mosaic.shape[0],\n",
    "        \"nodata\": nodata_value\n",
    "    })\n",
    "\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "    print(f\"Merged {len(tif_files)} TIF files with prefix {file_prefix} into {output_file}\")\n",
    "\n",
    "    # close & delete original TIF files & save bounds\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()\n",
    "    for tif_file in tif_files:\n",
    "        os.remove(tif_file)\n",
    "        print(f\"Deleted original TIF file: {tif_file}\")\n",
    "        \n",
    "    return tile_bounds\n",
    "\n",
    "\n",
    "def download_raster_tiles(tile_list_file, output_folder, name):\n",
    "    \"\"\"\n",
    "    Download DSM and DTM files for each tile specified in a text file.\n",
    "    ------\n",
    "    Input:\n",
    "    - tile_list_file (str): Path to the text file containing the list of tiles to download.\n",
    "    - output_folder (str): Directory where the downloaded and unzipped files will be saved.\n",
    "    - name (str): Name of the output raster file.\n",
    "    Output:\n",
    "    - tile_bounds (list): List containing the name of the tile and the extent of that tile, for downloading the buidling data.\n",
    "    - The function writes output files directly to the specified `output_folder`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Base URLs for downloading DTM and DSM tiles\n",
    "    base_url_dtm = \"https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/02a_DTM_0.5m\"\n",
    "    base_url_dsm = \"https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/03a_DSM_0.5m\"\n",
    "\n",
    "    # Read tile names from the text file\n",
    "    with open(tile_list_file, 'r') as f:\n",
    "        tile_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for tile_name in tile_names:\n",
    "        # Construct the URLs for DTM and DSM\n",
    "        # dtm_url = f\"{base_url_dtm}/M_{tile_name}.zip\"\n",
    "        dsm_url = f\"{base_url_dsm}/R_{tile_name}.zip\"\n",
    "\n",
    "        # Define file paths for downloaded zip files\n",
    "        # dtm_file_path = os.path.join(output_folder, f\"M_{tile_name}.zip\")\n",
    "        dsm_file_path = os.path.join(output_folder, f\"R_{tile_name}.zip\")\n",
    "\n",
    "        # Download and extract DTM and DSM files\n",
    "        # download_and_extract(dtm_url, dtm_file_path, output_folder)\n",
    "        download_and_extract(dsm_url, dsm_file_path, output_folder)\n",
    "\n",
    "    # Merge all DTM and DSM files separately after all downloads are done\n",
    "    # merged_dtm_output_file = os.path.join(output_folder, f\"{name}_DTM.TIF\")\n",
    "    merged_dsm_output_file = os.path.join(output_folder, f\"{name}_DSM.TIF\")\n",
    "\n",
    "    # Merge files starting with \"M_\" for DTM and \"R_\" for DSM\n",
    "    # merge_tif_files(output_folder, merged_dtm_output_file, \"M_\")\n",
    "    tile_bounds = merge_tif_files(output_folder, merged_dsm_output_file, \"R_\")\n",
    "\n",
    "    print(f\"All DTM and DSM files processed and merged.\")\n",
    "    \n",
    "    return tile_bounds\n"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:51:55.681336Z",
     "start_time": "2024-10-21T07:50:40.177340Z"
    }
   },
   "cell_type": "code",
   "source": "tile_bounds = download_raster_tiles(\"C:/Geomatics/shady_amsterdam/Calculating shade/Calculating_chm_dsm/ams_tiles_test.txt\", \"testingbounds\", \"deletethis\")",
   "id": "15d1ebacbf6c30eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/03a_DSM_0.5m/R_25DN1.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ns_hwh.fundaments.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved to testingbounds\\R_25DN1.zip\n",
      "Extracted testingbounds\\R_25DN1.zip\n",
      "Deleted the ZIP file: testingbounds\\R_25DN1.zip\n",
      "Downloading from https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/03a_DSM_0.5m/R_25DN2.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ns_hwh.fundaments.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved to testingbounds\\R_25DN2.zip\n",
      "Extracted testingbounds\\R_25DN2.zip\n",
      "Deleted the ZIP file: testingbounds\\R_25DN2.zip\n",
      "Merged 2 TIF files with prefix R_ into testingbounds\\deletethis_DSM.TIF\n",
      "Deleted original TIF file: testingbounds\\R_25DN1.TIF\n",
      "Deleted original TIF file: testingbounds\\R_25DN2.TIF\n",
      "All DTM and DSM files processed and merged.\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:51:55.692257Z",
     "start_time": "2024-10-21T07:51:55.686584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from owslib.wfs import WebFeatureService\n",
    "from shapely.geometry import box"
   ],
   "id": "6b3a5a31f6a85a8c",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:28:44.465764Z",
     "start_time": "2024-10-19T16:28:44.454753Z"
    }
   },
   "cell_type": "code",
   "source": "print(tile_bounds)",
   "id": "6cd328eafbf8df4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['25DN1', BoundingBox(left=110000.0, bottom=481250.0, right=115000.0, top=487500.0)], ['25DN2', BoundingBox(left=115000.0, bottom=481250.0, right=120000.0, top=487500.0)]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:51:55.723052Z",
     "start_time": "2024-10-21T07:51:55.712067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "\n",
    "def download_wfs_data(wfs_url, layer_name, bbox, output_gpkg, tile_name):\n",
    "    \"\"\"\n",
    "    Download data from a WFS server in batches and save it to a GeoPackage.\n",
    "    -----------------------------------------------------\n",
    "    Input:\n",
    "    -   wfs_url (str): URL of the WFS service.\n",
    "    -   layer_name (str): The layer name to download.\n",
    "    -   bbox (tuple): Bounding box as (minx, miny, maxx, maxy).\n",
    "    -   output_gpkg (str): Path to the output GeoPackage file.\n",
    "    -   tile_name (str): Layer name for saving in the GeoPackage.\n",
    "    Output:\n",
    "    -   None: saves a GeoPackage file to the given {output_gpkg} at layer {tile_name}.\n",
    "    \"\"\"\n",
    "    # Initialize variables for feature collection, max requestable amount from server is 10000\n",
    "    all_features = []\n",
    "    start_index = 0\n",
    "    count = 10000  \n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"SERVICE\": \"WFS\",\n",
    "            \"REQUEST\": \"GetFeature\",\n",
    "            \"VERSION\": \"2.0.0\",\n",
    "            \"TYPENAMES\": layer_name,\n",
    "            \"SRSNAME\": \"urn:ogc:def:crs:EPSG::28992\",\n",
    "            \"BBOX\": f\"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]},urn:ogc:def:crs:EPSG::28992\",\n",
    "            \"COUNT\": count,\n",
    "            \"STARTINDEX\": start_index\n",
    "        }\n",
    "\n",
    "        # Mimicking a QGIS request\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 QGIS/33411/Windows 11 Version 2009\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(wfs_url, params=params, headers=headers)\n",
    "\n",
    "        # Check if the request was successful & donwload data \n",
    "        if response.status_code == 200:\n",
    "            if response.headers.get('Content-Encoding', '').lower() == 'gzip' and response.content[:2] == b'\\x1f\\x8b':\n",
    "                data = gzip.decompress(response.content)\n",
    "            else:\n",
    "                data = response.content\n",
    "\n",
    "            with BytesIO(data) as f:\n",
    "                gdf = gpd.read_file(f)\n",
    "\n",
    "            all_features.append(gdf)\n",
    "\n",
    "            # Check if the number of features retrieved is less than the requested count: then we can stop\n",
    "            if len(gdf) < count:\n",
    "                break  \n",
    "\n",
    "            # Start index for next request\n",
    "            start_index += count\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to download WFS data. Status code: {response.status_code}\")\n",
    "            print(f\"Error message: {response.text}\")\n",
    "            break  \n",
    "        \n",
    "    # Concatenate all features into a single GeoDataFrame\n",
    "    if all_features:\n",
    "        full_gdf = gpd.GeoDataFrame(pd.concat(all_features, ignore_index=True))\n",
    "\n",
    "        # Saving to the GeoPackage with tile name\n",
    "        full_gdf.to_file(output_gpkg, layer=tile_name, driver=\"GPKG\")\n",
    "        print(f\"Downloaded and saved layer '{tile_name}' to {output_gpkg}\")\n",
    "    else:\n",
    "        print(\"No features were downloaded.\")"
   ],
   "id": "3f2448b1d83c7c32",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-21T07:51:55.741174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wfs_url = \"https://data.3dbag.nl/api/BAG3D/wfs\"\n",
    "output_gpkg = \"amsterdam\"\n",
    "layer_name = \"BAG3D:lod13\"\n",
    "for i in range(len(tile_bounds)):\n",
    "    tile_name = tile_bounds[i][0]\n",
    "    bbox = tile_bounds[i][1]\n",
    "    bbox_tuple = (bbox.left, bbox.bottom, bbox.right, bbox.top)\n",
    "    print(bbox_tuple)\n",
    "\n",
    "    download_wfs_data(\n",
    "        wfs_url=wfs_url,\n",
    "        layer_name=layer_name,\n",
    "        bbox=bbox_tuple,\n",
    "        output_gpkg=output_gpkg,\n",
    "        tile_name=tile_name\n",
    "    )"
   ],
   "id": "5b420f59742e0561",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110000.0, 481250.0, 115000.0, 487500.0)\n",
      "Downloaded and saved layer '25DN1' to amsterdam\n",
      "(115000.0, 481250.0, 120000.0, 487500.0)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:10:56.077925Z",
     "start_time": "2024-10-21T07:10:56.074471Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 30,
   "source": "import rasterio",
   "id": "6d455bf5fbbf7197"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
