{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T16:13:12.225128Z",
     "start_time": "2024-10-13T16:13:12.218654Z"
    }
   },
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import glob\n",
    "import cProfile\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import pstats\n",
    "\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "import functions"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FOR THE POINT CLOUDS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a093d51caab515d"
  },
  {
   "cell_type": "code",
   "source": [
    "def download_and_extract(url, file_path, output_folder):\n",
    "    \"\"\"Download a ZIP file from a URL, extract its contents, and delete the ZIP file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        try:\n",
    "            print(f\"Downloading from {url}...\")\n",
    "            response = requests.get(url, verify=False)  # Bypass SSL verification\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded and saved to {file_path}\")\n",
    "\n",
    "            # Extract the ZIP file\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(output_folder)  # Extract to the output folder\n",
    "            print(f\"Extracted {file_path}\")\n",
    "\n",
    "            # Remove the ZIP file after extraction\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted the ZIP file: {file_path}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {url}: {e}\")\n",
    "        except zipfile.BadZipFile as e:\n",
    "            print(f\"Failed to extract {file_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "def download_raster_tiles(tile_list_file, output_folder):\n",
    "    \"\"\"\n",
    "    Download DSM and DTM files for each tile specified in a text file.\n",
    "    ------\n",
    "    Input:\n",
    "    - tile_list_file (str): Path to the text file containing the list of tiles to download.\n",
    "    - output_folder (str): Directory where the downloaded and unzipped files will be saved.\n",
    "    Output:\n",
    "    - none:  The function writes output files directly to the specified `output_folder`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base URLs for downloading DTM and DSM tiles\n",
    "    base_url_dtm = \"https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/02a_DTM_0.5m\"\n",
    "    base_url_dsm = \"https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/03a_DSM_0.5m\"\n",
    "    \n",
    "    # Read tile names from the text file\n",
    "    with open(tile_list_file, 'r') as f:\n",
    "        tile_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for tile_name in tile_names:\n",
    "        # Construct the URLs for DTM and DSM\n",
    "        dtm_url = f\"{base_url_dtm}/M_{tile_name}.zip\"\n",
    "        dsm_url = f\"{base_url_dsm}/R_{tile_name}.zip\"\n",
    "        \n",
    "        # Define file paths for downloaded zip files\n",
    "        dtm_file_path = os.path.join(output_folder, f\"M_{tile_name}.zip\")\n",
    "        dsm_file_path = os.path.join(output_folder, f\"R_{tile_name}.zip\")\n",
    "        \n",
    "        # Download and extract DTM and DSM files\n",
    "        download_and_extract(dtm_url, dtm_file_path, output_folder)\n",
    "        download_and_extract(dsm_url, dsm_file_path, output_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T16:21:41.838346Z",
     "start_time": "2024-10-13T16:21:41.827637Z"
    }
   },
   "id": "1d8b18faed015786",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "download_raster_tiles(\"ams_tiles.txt\", \"../data\")",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T16:22:01.587914Z",
     "start_time": "2024-10-13T16:21:43.238495Z"
    }
   },
   "id": "641856c75294522e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/02a_DTM_0.5m/M_25BZ1.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ns_hwh.fundaments.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved to ../data\\M_25BZ1.zip\n",
      "Extracted ../data\\M_25BZ1.zip\n",
      "Deleted the ZIP file: ../data\\M_25BZ1.zip\n",
      "Downloading from https://ns_hwh.fundaments.nl/hwh-ahn/ahn4/03a_DSM_0.5m/R_25BZ1.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ns_hwh.fundaments.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m download_raster_tiles(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mams_tiles.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[14], line 59\u001B[0m, in \u001B[0;36mdownload_raster_tiles\u001B[1;34m(tile_list_file, output_folder)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# Download and extract DTM and DSM files\u001B[39;00m\n\u001B[0;32m     58\u001B[0m download_and_extract(dtm_url, dtm_file_path, output_folder)\n\u001B[1;32m---> 59\u001B[0m download_and_extract(dsm_url, dsm_file_path, output_folder)\n",
      "Cell \u001B[1;32mIn[14], line 6\u001B[0m, in \u001B[0;36mdownload_and_extract\u001B[1;34m(url, file_path, output_folder)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m     response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url, verify\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# Bypass SSL verification\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     response\u001B[38;5;241m.\u001B[39mraise_for_status()  \u001B[38;5;66;03m# Raise an error for bad responses\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\requests\\api.py:73\u001B[0m, in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \n\u001B[0;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, params\u001B[38;5;241m=\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\requests\\sessions.py:746\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    743\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[1;32m--> 746\u001B[0m     r\u001B[38;5;241m.\u001B[39mcontent\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\requests\\models.py:902\u001B[0m, in \u001B[0;36mResponse.content\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    900\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    901\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 902\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_content(CONTENT_CHUNK_SIZE)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    905\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[0;32m    906\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\requests\\models.py:820\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[1;34m()\u001B[0m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 820\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    822\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\response.py:1060\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[1;34m(self, amt, decode_content)\u001B[0m\n\u001B[0;32m   1058\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1059\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1060\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(amt\u001B[38;5;241m=\u001B[39mamt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content)\n\u001B[0;32m   1062\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[0;32m   1063\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\response.py:949\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[0;32m    946\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m amt:\n\u001B[0;32m    947\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer\u001B[38;5;241m.\u001B[39mget(amt)\n\u001B[1;32m--> 949\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raw_read(amt)\n\u001B[0;32m    951\u001B[0m flush_decoder \u001B[38;5;241m=\u001B[39m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[0;32m    953\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\response.py:873\u001B[0m, in \u001B[0;36mHTTPResponse._raw_read\u001B[1;34m(self, amt, read1)\u001B[0m\n\u001B[0;32m    870\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    872\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[1;32m--> 873\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp_read(amt, read1\u001B[38;5;241m=\u001B[39mread1) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    874\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[0;32m    875\u001B[0m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[0;32m    876\u001B[0m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[0;32m    883\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\urllib3\\response.py:856\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[1;34m(self, amt, read1)\u001B[0m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1()\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\http\\client.py:473\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[0;32m    471\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[0;32m    472\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[1;32m--> 473\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[0;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[0;32m    475\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    476\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    477\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\ssl.py:1314\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1310\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1311\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1312\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1313\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[0;32m   1315\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\ssl.py:1166\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1166\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1167\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1168\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# for the dsm and dtm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49847e88aff79478"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def download_files(tile_list_file):\n",
    "    \"\"\"\n",
    "    Download LAZ files for each tile specified in a text file.\n",
    "    \n",
    "    Input:\n",
    "    - tile_list_file (str): Path to the text file containing the list of tiles to download.\n",
    "    \"\"\"\n",
    "\n",
    "    base_url = \"https://geotiles.citg.tudelft.nl/AHN4_T\"\n",
    "\n",
    "    # Read tile names from the text file\n",
    "    with open(tile_list_file, 'r') as f:\n",
    "        tile_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    for full_tile_name in tile_names:\n",
    "        if '_' in full_tile_name:\n",
    "            tile_name, sub_tile = full_tile_name.split('_')\n",
    "        else:\n",
    "            print(f\"Skipping invalid tile entry: {full_tile_name}\")\n",
    "            continue\n",
    "\n",
    "        # Define folder structure and ensure it exists\n",
    "        folder = f\"../data/{tile_name}\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        # Construct the URL and file path\n",
    "        sub_tile_str = f\"_{int(sub_tile):02}\"  # Convert sub_tile to zero-padded two-digit number\n",
    "        url = f\"{base_url}/{tile_name}{sub_tile_str}.LAZ\"\n",
    "        filename = f\"{tile_name}{sub_tile_str}.LAZ\"\n",
    "        file_path = os.path.join(folder, filename)\n",
    "\n",
    "        # Check if file already exists to avoid re-downloading\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"File {file_path} already exists, skipping download.\")\n",
    "            continue\n",
    "\n",
    "        # Attempt to download the file\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded and saved {file_path}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {url}: {e}\")"
   ],
   "id": "4b07b280d2e3cb49"
  },
  {
   "cell_type": "code",
   "source": [
    "def merge_tif_files(input_folder, output_file, nodata_value=-9999):\n",
    "    tif_files = glob.glob(os.path.join(input_folder, '*.TIF'))\n",
    "\n",
    "    if not tif_files:\n",
    "        print(\"No TIF files found.\")\n",
    "        return\n",
    "\n",
    "    src_files_to_mosaic = []\n",
    "\n",
    "    for tif_file in tif_files:\n",
    "        src = rasterio.open(tif_file)\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    mosaic, out_transform = merge(src_files_to_mosaic)\n",
    "\n",
    "    # Replace existing nodata values with new nodata value if necessary\n",
    "    for src in src_files_to_mosaic:\n",
    "        if 'nodata' in src.meta:\n",
    "            mosaic[mosaic == src.nodata] = nodata_value\n",
    "\n",
    "    out_meta = src_files_to_mosaic[0].meta.copy()\n",
    "\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": mosaic.shape[1],\n",
    "        \"width\": mosaic.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"count\": mosaic.shape[0],  # Band count\n",
    "        \"nodata\": nodata_value  # Set the nodata value\n",
    "    })\n",
    "\n",
    "    # Write the merged file to the output path\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "    print(f\"Merged {len(tif_files)} TIF files into {output_file}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T15:42:17.058723Z",
     "start_time": "2024-09-23T15:42:17.043242Z"
    }
   },
   "id": "e260e5d87f09102b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "input_folder = \"data/DSM\"\n",
    "output_file = \"data/DSM_ams.TIF\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T15:42:17.075065Z",
     "start_time": "2024-09-23T15:42:17.058723Z"
    }
   },
   "id": "8754624cf933400e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "merge_tif_files(input_folder, output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T15:44:55.380464Z",
     "start_time": "2024-09-23T15:42:18.104407Z"
    }
   },
   "id": "5a6580eeb2e3a731",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 14 TIF files into data/DSM_ams.TIF\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T15:54:07.668935Z",
     "start_time": "2024-09-23T15:50:24.181369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_folder = \"data/DTM\"\n",
    "output_file = \"data/DTM_ams.TIF\"\n",
    "merge_tif_files(input_folder, output_file)"
   ],
   "id": "25d7c2e7024d724c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 14 TIF files into data/DTM_ams.TIF\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "\n",
    "def merge_tif_files(tif_files, output_file, nodata_value=-9999):\n",
    "    \"\"\"Merge specified TIF files and save as a single output file.\"\"\"\n",
    "    \n",
    "    if not tif_files:\n",
    "        print(\"No TIF files found.\")\n",
    "        return\n",
    "\n",
    "    src_files_to_mosaic = []\n",
    "\n",
    "    for tif_file in tif_files:\n",
    "        src = rasterio.open(tif_file)\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    mosaic, out_transform = merge(src_files_to_mosaic)\n",
    "\n",
    "    # Replace existing nodata values with new nodata value if necessary\n",
    "    for src in src_files_to_mosaic:\n",
    "        if 'nodata' in src.meta:\n",
    "            mosaic[mosaic == src.nodata] = nodata_value\n",
    "\n",
    "    out_meta = src_files_to_mosaic[0].meta.copy()\n",
    "\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": mosaic.shape[1],\n",
    "        \"width\": mosaic.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"count\": mosaic.shape[0],  \n",
    "        \"nodata\": nodata_value  \n",
    "    })\n",
    "\n",
    "    # Write the merged file to the output path\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "    print(f\"Merged {len(tif_files)} TIF files into {output_file}\")\n",
    "\n",
    "    # Clean up: delete the original files\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()  # Close the dataset\n",
    "        os.remove(src.name)  # Delete the original TIF file\n",
    "        print(f\"Deleted file: {src.name}\")\n",
    "\n",
    "def merge_and_cleanup(input_folder, output_dtm_file, output_dsm_file):\n",
    "    \"\"\"Merge M_ and R_ TIF files and clean up the original files.\n",
    "    ------\n",
    "    input: \n",
    "    - input_folder (string):    path to folder containing the seperate .tif files.\n",
    "    - output_dtm_file (string): path to output dtm file\n",
    "    output:\"\"\"\n",
    "    # Collect TIF files in the input folder\n",
    "    all_tif_files = glob.glob(os.path.join(input_folder, '*.TIF'))\n",
    "\n",
    "    # Filter M_ and R_ TIF files\n",
    "    m_tif_files = [f for f in all_tif_files if os.path.basename(f).startswith('M_')]\n",
    "    r_tif_files = [f for f in all_tif_files if os.path.basename(f).startswith('R_')]\n",
    "\n",
    "    # Merge M_ files\n",
    "    print(\"Merging M_ TIF files...\")\n",
    "    merge_tif_files(m_tif_files, output_m_file)\n",
    "\n",
    "    # Merge R_ files\n",
    "    print(\"Merging R_ TIF files...\")\n",
    "    merge_tif_files(r_tif_files, output_r_file)"
   ],
   "id": "ca179288f29aa5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
