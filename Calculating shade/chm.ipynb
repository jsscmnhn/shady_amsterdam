{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-17T13:44:42.138875100Z",
     "start_time": "2024-09-17T13:44:42.120401900Z"
    }
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import io\n",
    "import pstats\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "def extract_vegetation_points(LasData, ndvi_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Extract vegetation points based on classification and NDVI threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - LasData (laspy.LasData): Input point cloud data.\n",
    "    - ndvi_threshold (float): The NDVI threshold to classify vegetation.\n",
    "    \n",
    "    Returns:\n",
    "    - veg_points (laspy.LasData): Filtered vegetation points as a new LasData object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter points based on classification (vegetation-related classes)\n",
    "    possible_vegetation_points = LasData[(LasData.classification == 1) |  # Unclassified\n",
    "                                         (LasData.classification == 3) |  # Low vegetation\n",
    "                                         (LasData.classification == 4) |  # Medium vegetation\n",
    "                                         (LasData.classification == 5)]   # High vegetation\n",
    "\n",
    "    # Calculate NDVI\n",
    "    red = possible_vegetation_points.red\n",
    "    nir = possible_vegetation_points.nir\n",
    "    ndvi = (nir.astype(float) - red) / (nir + red)\n",
    "\n",
    "    # Filter the points whose NDVI is greater than the threshold\n",
    "    veg_points = possible_vegetation_points[ndvi > ndvi_threshold]\n",
    "\n",
    "    return veg_points\n",
    "\n",
    "def save_vegetation_points_as_las(LasData, output_file, veg_points, ndvi_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Extract vegetation points and save them as a new LAS file.\n",
    "    \n",
    "    Parameters:\n",
    "    - LasData (laspy.LasData): Input point cloud data.\n",
    "    - output_file (str): Path to the output LAS file.\n",
    "    - ndvi_threshold (float): NDVI threshold for vegetation points.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Extract vegetation points\n",
    "    \n",
    "    # Check if any points were filtered\n",
    "    if len(veg_points) == 0:\n",
    "        print(\"No vegetation points found with the given NDVI threshold.\")\n",
    "        return\n",
    "    \n",
    "    # Create a new LasData object for the vegetation points\n",
    "    veg_las_data = laspy.LasData(LasData.header)\n",
    "    veg_las_data.points = veg_points.points  # Assign the filtered vegetation points\n",
    "\n",
    "    # Save the vegetation points to a new LAS file\n",
    "    with laspy.open(output_file, mode=\"w\", header=veg_las_data.header) as writer:\n",
    "        writer.write_points(veg_las_data.points)\n",
    "    \n",
    "    print(f\"Vegetation points saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Load the LAS/LAZ file\n",
    "file_path = \"../data/25DN2_10.LAZ\"\n",
    "output_las = \"../data/output_vegetation.las\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T13:42:29.465273600Z",
     "start_time": "2024-09-17T13:42:29.445268200Z"
    }
   },
   "id": "2f57e08f5377567"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with laspy.open(file_path, laz_backend=laspy.LazBackend.Lazrs) as las_file:\n",
    "    las_data = las_file.read()\n",
    "\n",
    "veg_points = extract_vegetation_points(las_data, ndvi_threshold=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T13:43:26.294414500Z",
     "start_time": "2024-09-17T13:42:31.973966500Z"
    }
   },
   "id": "f698209d33d2b328"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:23:18.775226500Z",
     "start_time": "2024-09-17T14:23:18.772805Z"
    }
   },
   "id": "97f3eda85ddb3e8e"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def vegetation_raster_idw(LasData, points, resolution, search_radius=1, power=2):\n",
    "    \"\"\"\n",
    "    Create a vegetation raster using Inverse Distance Weighting (IDW) interpolation.\n",
    "\n",
    "    Parameters:\n",
    "    - LasData (laspy.LasData): Input LAS data.\n",
    "    - points (laspy.LasData): Vegetation points to be interpolated.\n",
    "    - center_point (tuple): Center coordinates (x, y) of the region of interest.\n",
    "    - resolution (float): Resolution of the raster.\n",
    "    - half_size (float): Half of the size of the tile (defines the extent of the raster).\n",
    "    - search_radius (float): Radius for the IDW search. Default is 1.\n",
    "    - power (float): Power parameter for the IDW algorithm. Default is 2.\n",
    "\n",
    "    Returns:\n",
    "    - vege_raster (np.ndarray): Generated raster for vegetation.\n",
    "    - grid_center_xy (tuple): Grid of x, y center coordinates for each raster cell.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the extents of the point cloud\n",
    "    min_x, max_x = round(LasData.x.min()), round(LasData.x.max())\n",
    "    min_y, max_y = round(LasData.y.min()), round(LasData.y.max())\n",
    "    \n",
    "    # Define the size of the region (half_size defines the full size as 2 * half_size)\n",
    "    x_length = max_x - min_x\n",
    "    y_length = max_y - min_y\n",
    "    \n",
    "    # Number of rows and columns based on the extents and resolution\n",
    "    cols = round(x_length / resolution)\n",
    "    rows = round(y_length / resolution)\n",
    "    \n",
    "    # Initialize the raster grid with NaN values (no data value)\n",
    "    vege_raster = np.full((rows, cols), np.nan, dtype=np.float32)\n",
    "\n",
    "    # Calculate the center coordinates for each grid cell\n",
    "    grid_center_xy = functions.raster_center_coords(min_x, max_x, min_y, max_y, resolution)\n",
    "\n",
    "    if len(points) == 0:\n",
    "        print(\"step4, vegetation_raster_idw: There are no vegetation points in the current area.\")\n",
    "        return vege_raster, grid_center_xy\n",
    "\n",
    "    # Convert the LAS points to a NumPy array for processing\n",
    "    points_list = np.array(points.xyz)  # Transform the laspy point cloud to numpy 2D array.\n",
    "\n",
    "    # Perform IDW interpolation using k-d tree\n",
    "    functions.interpolation_idw_kdtree(points_list, vege_raster, grid_center_xy, search_radius, power)\n",
    "\n",
    "    return vege_raster, grid_center_xy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:23:22.590500300Z",
     "start_time": "2024-09-17T14:23:22.587502Z"
    }
   },
   "id": "6bb75e9989f43236"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "243b877ff01d59f1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetation points saved to ../data/output_vegetation.las\n"
     ]
    }
   ],
   "source": [
    "save_vegetation_points_as_las(las_data, output_las, veg_points, ndvi_threshold=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T13:43:38.243238Z",
     "start_time": "2024-09-17T13:43:34.036180200Z"
    }
   },
   "id": "41f2181341c96e58"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def step4_main(LasData, veg_points, resolution=0.5, search_radius=1.0, idw_power=2.0, write_output=True, show_fig=False):\n",
    "\n",
    "    vege_points = extract_vegetation_points(LasData)\n",
    "    vegetation_data = vegetation_raster_idw(LasData, veg_points, resolution,\n",
    "                                             search_radius, idw_power)\n",
    "    veg_raster = vegetation_data[0]\n",
    "    grid_centers = vegetation_data[1]\n",
    "    top_left_x = grid_centers[0][0, 0] - resolution / 2\n",
    "    top_left_y = grid_centers[1][0, 0] + resolution / 2\n",
    "    if write_output:\n",
    "        transform = functions.create_affine_transform(top_left_x, top_left_y, resolution)\n",
    "        functions.write_output(vege_points, veg_raster, transform, \"../data/chm.tiff\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:28:54.036806500Z",
     "start_time": "2024-09-17T14:28:54.026953200Z"
    }
   },
   "id": "f2ea2ab514091310"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:22:12.533055300Z",
     "start_time": "2024-09-17T14:22:12.421254500Z"
    }
   },
   "id": "54d9e0fbf2d1c2b0"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[1;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 451, in __call__\n    for dumped_filename in dump(a, filename):\n                           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 553, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\pickle.py\", line 487, in dump\n    self.save(obj)\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 352, in save\n    wrapper.write_array(obj, self)\n  File \"C:\\Users\\jessi\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 134, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mPicklingError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m step4_main(las_data, veg_points, center_point\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m184420\u001B[39m, \u001B[38;5;241m420538\u001B[39m), half_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m250.0\u001B[39m, buffer_small\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25.0\u001B[39m,\n\u001B[0;32m      2\u001B[0m                resolution\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, search_radius\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m, idw_power\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.0\u001B[39m, write_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, show_fig\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[31], line 6\u001B[0m, in \u001B[0;36mstep4_main\u001B[1;34m(LasData, veg_points, center_point, half_size, buffer_small, resolution, search_radius, idw_power, write_output, show_fig)\u001B[0m\n\u001B[0;32m      4\u001B[0m center_x, center_y \u001B[38;5;241m=\u001B[39m center_point[\u001B[38;5;241m0\u001B[39m], center_point[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      5\u001B[0m vege_points \u001B[38;5;241m=\u001B[39m extract_vegetation_points(LasData)\n\u001B[1;32m----> 6\u001B[0m vegetation_data \u001B[38;5;241m=\u001B[39m vegetation_raster_idw(LasData, veg_points, center_point,resolution,\n\u001B[0;32m      7\u001B[0m                                         half_size, search_radius, idw_power)\n\u001B[0;32m      8\u001B[0m veg_raster \u001B[38;5;241m=\u001B[39m vegetation_data[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      9\u001B[0m grid_centers \u001B[38;5;241m=\u001B[39m vegetation_data[\u001B[38;5;241m1\u001B[39m]\n",
      "Cell \u001B[1;32mIn[29], line 45\u001B[0m, in \u001B[0;36mvegetation_raster_idw\u001B[1;34m(LasData, points, center_point, resolution, half_size, search_radius, power)\u001B[0m\n\u001B[0;32m     42\u001B[0m points_list \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(points\u001B[38;5;241m.\u001B[39mxyz)  \u001B[38;5;66;03m# Transform the laspy point cloud to numpy 2D array.\u001B[39;00m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Perform IDW interpolation using k-d tree\u001B[39;00m\n\u001B[1;32m---> 45\u001B[0m interpolation_idw_kdtree_parallel(points_list, vege_raster, grid_center_xy, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m vege_raster, grid_center_xy\n",
      "Cell \u001B[1;32mIn[28], line 22\u001B[0m, in \u001B[0;36minterpolation_idw_kdtree_parallel\u001B[1;34m(points_list, grid, grid_center_xy, search_radius, power, n_jobs)\u001B[0m\n\u001B[0;32m     18\u001B[0m grid_coords \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcolumn_stack((grid_center_x\u001B[38;5;241m.\u001B[39mravel(), grid_center_y\u001B[38;5;241m.\u001B[39mravel()))\n\u001B[0;32m     20\u001B[0m tree \u001B[38;5;241m=\u001B[39m cKDTree(points_list[:, :\u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m---> 22\u001B[0m interpolated_values \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs)(delayed(process_cell)(cell_center, points_list, tree, search_radius, power)\n\u001B[0;32m     23\u001B[0m                                              \u001B[38;5;28;01mfor\u001B[39;00m cell_center \u001B[38;5;129;01min\u001B[39;00m grid_coords)\n\u001B[0;32m     25\u001B[0m interpolated_grid \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(interpolated_values)\u001B[38;5;241m.\u001B[39mreshape(grid\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m interpolated_grid\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\parallel.py:1754\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_retrieval():\n\u001B[0;32m   1748\u001B[0m \n\u001B[0;32m   1749\u001B[0m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[0;32m   1751\u001B[0m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[0;32m   1752\u001B[0m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborting:\n\u001B[1;32m-> 1754\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_error_fast()\n\u001B[0;32m   1755\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1757\u001B[0m     \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m     \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\parallel.py:1789\u001B[0m, in \u001B[0;36mParallel._raise_error_fast\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1785\u001B[0m \u001B[38;5;66;03m# If this error job exists, immediately raise the error by\u001B[39;00m\n\u001B[0;32m   1786\u001B[0m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[0;32m   1788\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1789\u001B[0m     error_job\u001B[38;5;241m.\u001B[39mget_result(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\parallel.py:745\u001B[0m, in \u001B[0;36mBatchCompletionCallBack.get_result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    739\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel\u001B[38;5;241m.\u001B[39m_backend\n\u001B[0;32m    741\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39msupports_retrieve_callback:\n\u001B[0;32m    742\u001B[0m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[0;32m    743\u001B[0m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[1;32m--> 745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return_or_raise()\n\u001B[0;32m    747\u001B[0m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\synthesis\\Lib\\site-packages\\joblib\\parallel.py:763\u001B[0m, in \u001B[0;36mBatchCompletionCallBack._return_or_raise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    762\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m TASK_ERROR:\n\u001B[1;32m--> 763\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    764\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    765\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[1;31mPicklingError\u001B[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "step4_main(las_data, veg_points, resolution=0.5, search_radius=1.0, idw_power=2.0, write_output=True, show_fig=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:27:21.206237Z",
     "start_time": "2024-09-17T14:23:35.403460600Z"
    }
   },
   "id": "281d972f707d3e44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
